{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# set defaults\n",
    "plt.style.use('seaborn-white')   # seaborn custom plot style\n",
    "plt.rc('figure', dpi=100, figsize=(7, 5))   # set default size/resolution\n",
    "plt.rc('font', size=12)   # font size\n",
    "\n",
    "tips = sns.load_dataset('tips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Examples\n",
    "\n",
    "Outline\n",
    "\n",
    "* Grid Search / Classification.\n",
    "* Regression with feature selection (multicollinearity)\n",
    "* Text model (bag of words /  tfidf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Predicting Diabetes\n",
    "\n",
    "* Given health measurements, can you predict whether an individual will develop diabetes?\n",
    "* Classification of health outcomes: 0=NO DIABETES and 1=DIABETES\n",
    "* We will use 'accuracy' to evaluate the model (not necessarily the best choice!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('data/diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes[['Pregnancies','Insulin', 'BMI', 'Glucose', 'Outcome']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "X = diabetes.drop('Outcome', axis=1)\n",
    "# outcome\n",
    "y = diabetes.Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion for correct values\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the importance of each feature in our tree model\n",
    "# _: attributes created when model is fit. Contains info that it learned from the data\n",
    "dict(zip(X.columns, clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum depth\n",
    "clf.tree_.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node count\n",
    "clf.tree_.node_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_small = DecisionTreeClassifier(max_depth=4)\n",
    "clf_small.fit(X_train, y_train)\n",
    "clf_small.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_small.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import tree_to_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_to_code(clf_small, X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_to_code(clf, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to select model parameters?\n",
    "\n",
    "* Each combination of model parameters requires: \n",
    "    - fitting a model; evaluating the model; comparing performance.\n",
    "* This leads to training perhaps *thousands* of models!\n",
    "    - How to do this in a computationally feasible way?\n",
    "    - How to keep your code clean to keep track?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to select model parameters?\n",
    "\n",
    "* How to select in a computationally feasible way?\n",
    "    - Trying every combination ('grid search') works for smaller data/models.\n",
    "    - Sampling possible combinations of parameters using probabilistic reasoning.\n",
    "    \n",
    "* How to keep your code clean to keep track?\n",
    "    - The `sklearn.model_selection` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: parameter search for diabetes prediction\n",
    "\n",
    "* Decision tree has possible parameters:\n",
    "    - `max_depth`, `min_samples_split`, `min_samples_leaf`\n",
    "    - plus others we won't consider\n",
    "    \n",
    "* We will use `GridSearchCV` to explore parameter combinations using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many combinations are there to search through?\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [2,3,4,5,7,10,13,15,18,None], \n",
    "    'min_samples_split':[2,3,5,7,10,15,20],\n",
    "    'min_samples_leaf':[2,3,5,7,10,15,20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(v) for v in parameters.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(DecisionTreeClassifier(), parameters, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf#.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of competing models\n",
    "len(clf.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of models fit = (# of param combos) x (5 folds)\n",
    "490 * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Was the \"best parameter\" the only \"best choice\"\n",
    "\n",
    "* Plot the histogram of scores across all models\n",
    "* Many high values implies many good model choices\n",
    "    - Robust model\n",
    "* Plot the histogram of standard deviations for the CVs\n",
    "    - many small numbers imply most parameters give stable models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each x-value is the score of a different model,\n",
    "# corresponding to a choice of parameters\n",
    "#\n",
    "plt.hist(clf.cv_results_['mean_test_score'], bins=12)\n",
    "plt.suptitle('accuracies on validation set for CV');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if many models were good and had high accuracy => good\n",
    "# you do not want a model that really depends on parameter choices => likely, overfitting\n",
    "# if a lot of good model choices: you are learning real patterns in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each x-value is the standard deviation for the 5-fold CV for a single model\n",
    "# corresponding to a choice of parameters\n",
    "plt.hist(clf.cv_results_['std_test_score'])\n",
    "plt.suptitle('std deviation of CV scores');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we have a high std of accuracy: model varied a lot, depending on how \n",
    "# you split your data.\n",
    "# If std is low, then you are getting the same model performace \n",
    "# ^^ tells you what you should expect for fluctuation in your accuracy above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_best = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_to_code(clf_best, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression with Multicollinearity\n",
    "\n",
    "* Linear regression with (perfectly) correlated features leads to high variance (unstable) models.\n",
    "* When the dataset ~1-dimensional in 3-dim space, fitting a plane is under-determined.\n",
    "* Regression gives you a plane of best fit but there are other planes that will give very similar error when fitting it that look very different: overfit model\n",
    "* Use Principal Component Analysis to drop unneeded features.\n",
    "\n",
    "<img src=\"imgs/multicollinearity.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression: predicting tips data\n",
    "\n",
    "* Use quantitative feature \"as is\".\n",
    "* Use all features: one-hot encode categorical features.\n",
    "    - Many perfectly correlated features: e.g. `is_Lunch` and `is_Dinner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = sns.load_dataset('tips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Determining Correlated features\n",
    "\n",
    "How many columns can we keep without losing information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcols = ['sex', 'smoker', 'day', 'time']\n",
    "pd.get_dummies(tips).head()      # only use get_dummies for illustration, NOT model building!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Creating a Regression Pipeline\n",
    "* Drop correlated features using Principal Component Analysis (PCA)\n",
    "* Categorical Variables: One-Hot Encoding => PCA (drop correlated features)\n",
    "* Quantitative Variables: Pass-through\n",
    "* Estimator: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd_solver: how much information do you want to drop\n",
    "# default: drops nothing\n",
    "cats = Pipeline([\n",
    "    ('ohe', OneHotEncoder(sparse=False)), \n",
    "    ('pca', PCA(svd_solver='full'))\n",
    "])\n",
    "catcols = ['sex', 'smoker', 'day', 'time']\n",
    "\n",
    "nums = FunctionTransformer(lambda x:x)\n",
    "numcols = ['total_bill', 'size']\n",
    "\n",
    "ct = ColumnTransformer([('cat', cats, catcols), ('num', nums, numcols)])\n",
    "\n",
    "pl = Pipeline([('feats', ct), ('lr', LinearRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Use Parameter Grid-Search with Cross-Validation\n",
    "\n",
    "* Inspect the parameters of the pipeline with `get_params`: use to get keys for parameter-grid.\n",
    "* Train models using a grid search and analyze the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None: keep all variables\n",
    "# 0.90 : keep 90% of the information\n",
    "params = {'feats__cat__pca__n_components':[.8, .85, .9, .95, None]}\n",
    "grids = GridSearchCV(pl, param_grid=params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_ts, y_tr, y_ts = train_test_split(tips, tips.tip)\n",
    "grids.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best_score_ is the average over your cross-validation fold scores of the best model \n",
    "# (best in exactly that sense: scores highest on average over folds)\n",
    "grids.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids.best_estimator_.score(X_ts, y_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Housing Price Prediction: Sales Price from House Characteristics\n",
    "\n",
    "* Create a 'baseline' model: a model pipeline without ingenuity.\n",
    "* Try to improve upon the the baseline with creativity and domain knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('data/housing.csv')\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop id and SalesPrice from features\n",
    "\n",
    "X = housing.drop(['Id', 'SalePrice'], axis=1)\n",
    "y = housing['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Baseline Model\n",
    "\n",
    "* Do the 'minimum' to fit a model and check the performance.\n",
    "    - Quantitative: impute with zero and pass-through (Why is zero not a *terrible* choice?)\n",
    "    - Categorical: One-hot encoding (what assumption is this making about the data?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = X.dtypes\n",
    "catcols = types.loc[types == np.object].index\n",
    "numcols = types.loc[types != np.object].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='constant', fill_value='NULL')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
    "#    ('pca', PCA(svd_solver='full', n_components=0.99))\n",
    "])\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('catcols', cats, catcols),\n",
    "    ('numcols', SimpleImputer(strategy='constant', fill_value=0), numcols)\n",
    "])\n",
    "\n",
    "pl = Pipeline([('feats', ct), ('reg', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fit(X_tr, y_tr)\n",
    "pl.score(X_ts, y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pl.predict(X_ts)\n",
    "np.sqrt(np.mean(preds - y_ts)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "for _ in range(100):\n",
    "    X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.25)\n",
    "    pl.fit(X_tr, y_tr)\n",
    "    out.append(pl.score(X_ts, y_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(out).plot(kind='hist', title='scores in 100 model builds', bins=np.linspace(0, 1, 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Improved Model\n",
    "\n",
    "Question: What features and model improvements can we use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Improved Model\n",
    "\n",
    "* If using linear regression: PCA to drop extra information.\n",
    "* Better techniques for categorical encoding? (Ordinal vs Nominal?)\n",
    "* Better techniques for imputation?\n",
    "* Other models to try? (Tree-based?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "cats = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='constant', fill_value='NULL')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
    "    ('pca', PCA(svd_solver='full', n_components=0.99))\n",
    "])\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('catcols', cats, catcols),\n",
    "    ('numcols', SimpleImputer(strategy='constant', fill_value=0), numcols)\n",
    "])\n",
    "\n",
    "pl = Pipeline([('feats', ct), ('reg', RandomForestRegressor())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fit(X_tr, y_tr)\n",
    "pl.score(X_ts, y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pl.predict(X_ts)\n",
    "np.sqrt(np.mean(preds - y_ts)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predicting Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_json(open('data/reviews.json'), lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reviews['summary']\n",
    "y = (reviews[['overall']] > 3).astype(int)\n",
    "\n",
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec.fit(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(count_vec.vocabulary_, key=lambda x:x[1])\n",
    "\n",
    "pd.DataFrame(\n",
    "    data=count_vec.transform(X).toarray(),\n",
    "    columns=vocab\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('cv', CountVectorizer()), \n",
    "    ('clf', RandomForestClassifier(max_depth=8, n_estimators=7))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.score(X_ts, y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pl.named_steps['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the most important features?\n",
    "pd.Series(\n",
    "    data=clf.feature_importances_,\n",
    "    index=vocab\n",
    ").sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'annoy'\n",
    "\n",
    "reviews[reviews['summary'].str.lower().str.contains(word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[reviews['summary'].str.lower().str.contains(word)].overall.plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'clf__max_depth': np.arange(2,500,20)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = GridSearchCV(pl, param_grid=params, cv=3, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = grids.param_grid['clf__max_depth']\n",
    "test = grids.cv_results_['mean_test_score']\n",
    "train = grids.cv_results_['mean_train_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'test': test, 'train': train}, index=index).plot()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
