{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Information Extraction: Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: San Diego City Employee Salaries\n",
    "* Recall Lecture 01: Do men and women make similar salaries?\n",
    "* Follow-up question: Do men and women make similar salaries among those with similar jobs?\n",
    "    - How to determine \"similar jobs?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = pd.read_csv('https://transcal.s3.amazonaws.com/public/export/san-diego-2017.csv')\n",
    "jobtitles = salaries['Job Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles.value_counts().iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles.shape[0], jobtitles.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles.value_counts().iloc[:100].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cleaning job titles: assessment\n",
    "* Can we canonicalize job titles?\n",
    "* Are they self-consistent?\n",
    "    - Punctuation? Capitalization? Abbreviations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run / rerun\n",
    "jobtitles.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cleaning job titles: step 1\n",
    "* Is every first letter capitalized?\n",
    "* What punctuation exists? should it be cleaned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capitalization\n",
    "jobtitles[(\n",
    "    jobtitles.str.contains(' [a-z]+ ') | \n",
    "    jobtitles.apply(lambda x:x[0].islower())\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# punctuation: replace with space?\n",
    "jobtitles[jobtitles.str.contains('[^A-Za-z0-9 ]')].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cleaning job titles: step 1\n",
    "* Remove: to, the, for\n",
    "* Replace: non-alphanumeric with space\n",
    "* Replace multiple spaces with one space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles = (\n",
    "    jobtitles\n",
    "    .str.replace(' to| the| for', '')  # include the spaces! (why?)\n",
    "    .str.replace(\"[^A-Za-z0-9' ]\", ' ')\n",
    "    .str.replace(\"'\", '')\n",
    "    .str.replace(' +', ' ')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cleaning job titles: abbreviations \n",
    "\n",
    "* Which job titles are inconsistently described?\n",
    "    - Librarian? Engineer? Director?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles[jobtitles.str.contains('Libr')].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles[jobtitles.str.contains('Eng')].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles[jobtitles.str.contains('Dir')].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The limits of canonicalization\n",
    "* How do we find which common words to map a job title to?\n",
    "    - E.g. pattern matching on 'Eng' or 'Libr'\n",
    "* What about other titles? (there are too many!)\n",
    "* Adjectives vs Nouns have different meanings\n",
    "    - Junior/Senior/Director vs Police/Fire/Engineer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The limits of canonicalization\n",
    "\n",
    "Naive procedure: \n",
    "1. Compute most common words (distribution of words in the dataset)\n",
    "2. Select \"relevant\" words using domain expertise  (Police vs Asst)\n",
    "3. Check if a given word is contained in a given job title.\n",
    "\n",
    "E.g.: \"fire\", \"police\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts of all words (together)\n",
    "bow = jobtitles.str.split().sum()    #splits on space and sums\n",
    "#bow\n",
    "words = pd.Series(bow).value_counts()\n",
    "#words\n",
    "words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is a given word in a job-title? count number of occurances of each\n",
    "jobtypes = pd.DataFrame([], index=salaries.index)\n",
    "for word in words.index:\n",
    "    re_pat = '\\\\b{val}\\\\b'.format(val = word)\n",
    "    jobtypes[word] = jobtitles.str.count(re_pat).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of counts each word appear in every row\n",
    "jobtypes.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many columns? (curse of dimensionality)\n",
    "\n",
    "len(jobtypes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of job titles that contained that word\n",
    "# most common 20 words\n",
    "jobtypes.iloc[:,:20].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does this represent?\n",
    "# most common 20 words\n",
    "# What about those with sum = 0? sum > 1?\n",
    "jobtypes.iloc[:,:20].sum(axis=1)#.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problem\n",
    "\n",
    "- Manually finding all keywords (fire, police, etc.) is labor intensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bags of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What are the closest job titles to 'Asst Fire Chief'\n",
    "\n",
    "\n",
    "* Idea: which other job titles share \"the most\" words in common?\n",
    "* Implementation: use the 'word vectors' in `jobtypes` to count up matching words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the closest job titles to:\n",
    "jobidx = 76\n",
    "job = jobtitles.iloc[jobidx]\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job1 = jobtitles.iloc[0]\n",
    "job1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word vectors side-by-side\n",
    "pd.concat([jobtypes.iloc[0], jobtypes.iloc[76]], axis=1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply\n",
    "\n",
    "cnts = pd.concat([jobtypes.iloc[0], jobtypes.iloc[76]], axis=1)\n",
    "\n",
    "(cnts.iloc[:,0] * cnts.iloc[:,1]).head(10).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum the matches\n",
    "np.sum(cnts.iloc[:,0] * cnts.iloc[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution attempt 1: bag of words\n",
    "1. Create a list of all words appearing among *all* text ('bag of words')\n",
    "2. Create a vector, indexed by the distinct words, with counts of the words in that entry.\n",
    "3. Two text entries are similar if the sum of their matches is large.\n",
    "    - The sum of their matches is the same as the dot-product of the vectors!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion Question\n",
    "\n",
    "Given the list of sentences below:\n",
    "1. What is the index for the word vectors of the sentences?\n",
    "2. How close are the word-vectors of the first and second sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'the fox and the moon',\n",
    "    'the cow and the moon',\n",
    "    'the cow and the spoon'\n",
    "]\n",
    "pd.Series(sentences).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.Series(sentences)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.Series(sentences.str.split().sum()).value_counts()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvecs = pd.DataFrame([], index=sentences.index)\n",
    "for word in words.index:\n",
    "    re_pat = '\\\\b%s\\\\b' % word\n",
    "    wordvecs[word] = sentences.str.count(re_pat).astype(int)\n",
    "    \n",
    "wordvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(wordvecs.iloc[0] * wordvecs.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bag of Words: Salaries\n",
    "* Compute the sum of matches among all word vectors and 'Asst Fire Chief'\n",
    "* Take the job that is the closest match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles.iloc[jobidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobvec = jobtypes.iloc[jobidx]\n",
    "jobvec.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot product with 'Asst Fire Chief' and *all* other titles\n",
    "matches = jobtypes.apply(lambda ser: np.dot(jobvec, ser), axis=1)\n",
    "matches.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles.loc[matches.sort_values(ascending=False).index].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary: Bag of Words\n",
    "\n",
    "* Create an index out of *all* distinct words \n",
    "    - The basis for the vector space of words.\n",
    "* Create vectors for each text entry by computing the counts of words in the entry.\n",
    "* The dot product between two vectors is proportional to their 'similarity':\n",
    "    - This defines the **cosine distance** between vectors via: $$dist(v, w) = 1 - \\cos(\\theta) = 1 - \\frac{v \\cdot w}{|v||w|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conclusion: Bag of Words\n",
    "* Bag of words *embeds words into a vector space*\n",
    "* Can then use clustering (e.g. k-means) to group like words (e.g. into 'job-types')\n",
    "    - Unfortunately, many clustering techniques don't work well in high dimensions.\n",
    "* Downside: treats all words as *equally important*.\n",
    "    - \"Asst Fire Chief\" vs \"Asst Chief Oper Ofcr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TF-IDF\n",
    "\n",
    "Term Frequency / Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Term Frequency, Inverse Document Frequency\n",
    "\n",
    "How do we figure out which words are \"important\" in a document?\n",
    "\n",
    "1. The most common words often *don't* have much meaning!\n",
    "2. The very rare words are also less important!\n",
    "\n",
    "Goal: balance these two observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Term Frequency, Inverse Document Frequency\n",
    "\n",
    "* The *term frequency* of a word $t$ in a document $d$, denoted ${\\rm tf}(t,d)$, is the likelihood of the term appearing in the document.\n",
    "   * Word that occurs often is important to document meaning.\n",
    "\n",
    "* The *document frequency* is how often the a words occurs in the entire set of documents.\n",
    "   * Common words that appear everywhere.\n",
    "\n",
    "\n",
    "* Question: what are the frequencies for a word \"the\"? (high/low?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What about their ratio? Intuition\n",
    "\n",
    "The relevance of this word to the document.\n",
    "\n",
    "$$\\frac{{\\rm\\ TermFrequency}}{{\\rm DocumentFrequncy}}$$\n",
    "\n",
    "* `TF`: High, `DC`: High\n",
    "* `TF`: High, `DC`: Low\n",
    "* `TF`: Low, `DC`: High\n",
    "* `TF`: Low, `DC`: Low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Term Frequency, Inverse Document Frequency\n",
    "\n",
    "* The *term frequency* of a word $t$ in a document $d$, denoted ${\\rm tf}(t,d)$, is the likelihood of the term appearing in the document.\n",
    "* The *inverse document frequency* of a word $t$ in a set of documents $\\{d_i\\}$, denoted ${\\rm idf}(t,d)$ is: \n",
    "\n",
    "$$\\log(\\frac{{\\rm\\ total\\ number\\ of\\ documents}}{{\\rm number\\ of\\ documents\\ in\\ which\\ t\\ appears}})$$\n",
    "\n",
    "* The *tf-idf* of a term $t$ in document $d$ is given by the product: \n",
    "\n",
    "$${\\rm tfidf}(t,d) = {\\rm tf}(t,d) \\cdot {\\rm idf}(t)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the tf-idf of 'cow' in the second 'document'?\n",
    "sentences.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the term frequency of 'cow' in the second 'document'\n",
    "tf = sentences.iloc[1].count('cow') / (sentences.iloc[1].count(' ') + 1)\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = np.log(len(sentences) / sentences.str.contains('cow').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf * idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### TF-IDF of all terms in all documents\n",
    "* What are the different reasons tf-idf can be zero?\n",
    "* When is it the largest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.Series(sentences.str.split().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = pd.DataFrame([], index=sentences.index)  # dataframe of documents\n",
    "for w in words.unique():\n",
    "    re_pat = '\\\\b%s\\\\b' % w\n",
    "    tf = sentences.str.count(re_pat) / (sentences.str.count(' ') + 1)\n",
    "    idf = np.log(len(sentences) / sentences.str.contains(re_pat).sum())\n",
    "    tfidf[w] = tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: TF-IDF\n",
    "\n",
    "* Term Frequency, Inverse Document Frequency balances:\n",
    "    - how often a word appears in a document/sentence, with\n",
    "    - how often a word appears *across* documents.\n",
    "* For a given document, the word with the highest TF-IDF best summarizes that document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: State of the Union Addresses\n",
    "\n",
    "* What are the important words for each address?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "sotu = open('data/stateoftheunion1790-2017.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sotu[:20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = sotu.split('\\n***\\n')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(speeches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_struct(speech):\n",
    "    L = speech.strip().split('\\n', maxsplit=3)\n",
    "    L[3] = re.sub(\"[^A-Za-z' ]\", ' ', L[3]).lower()\n",
    "    return dict(zip(['speech', 'president', 'date', 'contents'], L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(map(extract_struct, speeches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.Series(df.contents.str.split().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = pd.DataFrame([], index=df.index)  # dataframe of documents\n",
    "tf_denom = (df.contents.str.count(' ') + 1)\n",
    "for w in words.value_counts().iloc[0:500].index:\n",
    "    # imperfect pattern match for speed\n",
    "    re_pat = ' %s ' % w\n",
    "    tf = df.contents.str.count(re_pat) / tf_denom\n",
    "    idf = np.log(len(df) / df.contents.str.contains(re_pat).sum())\n",
    "    tfidf[w] =  tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = tfidf.idxmax(axis=1)\n",
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.iloc[0].argsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_largest(row):\n",
    "    return list(row.index[row.argsort()][-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = tfidf.apply(five_largest, axis=1)\n",
    "keywords_df = pd.concat([\n",
    "    df['president'],\n",
    "    keywords\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "with pd.option_context('display.max_rows', 300):\n",
    "    display(keywords_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Features\n",
    "\n",
    "* A **feature** is a measurable property or characteristic of a phenomenon being observed.\n",
    "* Synonyms: (explanatory) variable, attribute\n",
    "* Examples include:\n",
    "    - a column of a dataset.\n",
    "    - a derived value from a dataset, perhaps using additional information.\n",
    "    \n",
    "We have been creating features to summarize data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Examples of features in SD salary dataset\n",
    "\n",
    "* Salary of employee\n",
    "* Employee salaries, standardized by job status (PT/FT)\n",
    "* Gender/age of employees (derived from SSA names; accurate?)\n",
    "* Job Family associated to a job title (uses text-techniques)\n",
    "* TF-IDF summary of each state of the union address (topic modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What makes a good feature?\n",
    "\n",
    "* Fidelity to Data Generating Process (Consistency).\n",
    "* Strongly associated to phenomenon of interest (\"contains information\").\n",
    "* Easily used in standard modeling techniques (e.g. quantitative and scaled).\n",
    "\n",
    "Datasets often come with weak attributes; features may need to be \"engineered\" to convey information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature Engineering\n",
    "\n",
    "* The process of creating effective, quantitative attributes from data.\n",
    "* Transforming heterogeneous data into quantitative data is required for statistical models!\n",
    "* Similar observations in the data should transform to nearby points in the (Euclidean) feature space.\n",
    "\n",
    "Effective feature engineering makes (relationships in) data easy to understand!\n",
    "- Either for a statistical model, or visually for the data scientist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The goal of feature engineering\n",
    "\n",
    "* Find transformations that effectively transform data into effective quantitative variables\n",
    "\n",
    "* Find functions $\\phi:{\\rm DATA}\\to\\mathbb{R}^d$ where similar points $x,y\\in {\\rm DATA}$ have close images $\\phi(x), \\phi(y)\\in \\mathbb{R}^d$\n",
    "\n",
    "* A \"good\" choice of features depends on many factors:\n",
    "    - data type (quantitative, ordinal, nominal),\n",
    "    - the relationship(s) and association(s) being modeled,\n",
    "    - the model type (e.g. linear models, decision tree models, neural networks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Want to build a linear model:\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "    \n",
    "* on a dataset of product review data (X),\n",
    "* to understand the relationship to product ratings (Y).\n",
    "\n",
    "<img src=\"imgs/plane.jpg\">\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Want to build a linear model\n",
    "\n",
    "* Why can't a linear model be built review data directly?\n",
    "* What needs to happen to build the model?\n",
    "* What are concrete steps to take?\n",
    "\n",
    "|UID|AGE|STATE|HAS_BOUGHT|REVIEW|\\||RATING|\n",
    "|---|---|---|---|---|---|---|\n",
    "|0|32|NY|True|\"Meh.\"|\\||&#10025;&#10025;|\n",
    "|42|50|WA|True|\"Worked out of the box...\"|\\||&#10025;&#10025;&#10025;&#10025;|\n",
    "|57|16|CA|NULL|\"Hella tots lit yo...\"|\\||&#10025;|\n",
    "|...|...|...|...|...|\\||...|\n",
    "|(int)|(int)|(str)|(bool)|(str)|\\||(str)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Basic Transformations: uninformative features\n",
    "\n",
    "`UID` was likely used to join the user information (e.g., `age`, and `state`) with some `Reviews` table.  The `UID` presents several questions:\n",
    "* What is the meaning of the `UID` *number*? \n",
    "* Does the magnitude of the `UID` reveal information about the rating?\n",
    "* Does adding `UID` improve our model?\n",
    "* **Transformation:** drop the feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dropping Features\n",
    "\n",
    "There are certain scenarios where manually dropping features might be helpful:\n",
    "\n",
    "1. when the features **does not to contain information** associated with the prediction task.  \n",
    "2. when the feature is **not available at prediction time.**  For example, the feature might contain information collected after the user entered a rating.  This is a common scenario in time-series analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Basic Transformations: scaling features\n",
    "\n",
    "`AGE` might contain corrupted or 'clumped' data that requires scaling:\n",
    "- **Transformation:** apply binning to discretize the data into quartiles.\n",
    "- **Transformation:** apply non-linear transformation (e.g. log, sqrt).\n",
    "- **Transformation:** normalize/standardize (z-scale; range)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Basic Transformations: ordinal encoding\n",
    "\n",
    "How to encode the `RATING` column as a quantitative variable?\n",
    "* **Transformation:** \"number of &#10025;\" to \"number\".\n",
    "    - Called *ordinal encoding*: map the ordinal values onto the integer, preserving order.\n",
    "* Does this preserve \"distances\" between ratings? (yes).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_values = ['✩', '✩✩', '✩✩✩', '✩✩✩✩', '✩✩✩✩✩']\n",
    "ordinal_enc = {y:x for (x,y) in enumerate(order_values)}\n",
    "ordinal_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.RATING.replace(ordinal_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Basic Transformations: one-hot encoding\n",
    "\n",
    "How to encode the `STATE` column as a quantitative variable?\n",
    "- How do we make STATE into a meaningful number?\n",
    "- Ordinal Encoding? AL=1,...,WY=50? (No!)\n",
    "- **Transformation:** 50 binary variables: `is_AL`,...,`is_WY`.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nominal feature encoding: One hot encoding\n",
    "\n",
    "* Transform categorical features into many binary features.\n",
    "* Given a column `col` with values `A1,A2,...A_N`, define the following quantitative binary columns:\n",
    "\n",
    "$$\\phi_i(x) = \\left\\{\\begin{array}{ll}1 & {\\rm if\\ } x = A1 \\\\ 0 &  {\\rm if\\ } x\\neq A1 \\\\ \\end{array}\\right. $$\n",
    "\n",
    "* *Also called:* dummy encoding; indicator variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: one hot encoding `STATE`\n",
    "\n",
    "<div class=\"txt-image-container\">\n",
    "\n",
    "* A column containing US states transforms into 50 feature columns\n",
    "* e.g. `phi_CA(x) = 1 if x == 'CA' else 0`\n",
    "* Each row has *exactly one 1*.\n",
    "* Many of these columns will be *largely* 0.\n",
    "\n",
    "<img src=\"imgs/one-hot.png\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([['NY'], ['WA'], ['CA'], ['NY'], ['OR']], columns=['STATE'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = df.STATE.unique()\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['STATE'].apply(lambda x: pd.Series(x == states, index=states, dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
